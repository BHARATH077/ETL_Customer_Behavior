{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa8N9PQGxHveRELBNRFMqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BHARATH077/ETL_Customer_Behavior/blob/main/customer_etl_dag_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Airflow Orchestration (Simulated)"
      ],
      "metadata": {
        "id": "xiXHsMTnvq7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: DAG Setup\n",
        "### Airflow uses Directed Acyclic Graphs (DAGs) — a set of tasks that run in order.\n",
        "### We’ll define:\n",
        "- Extract → Load raw CSV data.\n",
        "- Transform → Clean & enrich Customer 360.\n",
        "- Load → Save CSV for dashboarding."
      ],
      "metadata": {
        "id": "t5yq4tMTviBK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA1AewIXvbRA"
      },
      "outputs": [],
      "source": [
        "#Step 2: Create DAG Script\n",
        "\n",
        "from airflow import DAG\n",
        "from airflow.operators.python import PythonOperator\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# ---- ETL Task Functions ----\n",
        "def extract():\n",
        "    # In real scenario: load from API, DB, etc.\n",
        "    clickstream = pd.read_csv(\"clickstream.csv\")\n",
        "    transactions = pd.read_csv(\"transactions.csv\")\n",
        "    crm = pd.read_csv(\"crm.csv\")\n",
        "    clickstream.to_csv(\"/tmp/clickstream_raw.csv\", index=False)\n",
        "    transactions.to_csv(\"/tmp/transactions_raw.csv\", index=False)\n",
        "    crm.to_csv(\"/tmp/crm_raw.csv\", index=False)\n",
        "\n",
        "def transform():\n",
        "    clickstream = pd.read_csv(\"/tmp/clickstream_raw.csv\")\n",
        "    transactions = pd.read_csv(\"/tmp/transactions_raw.csv\")\n",
        "    crm = pd.read_csv(\"/tmp/crm_raw.csv\")\n",
        "\n",
        "    # Example transformation: aggregate spend\n",
        "    spend = transactions.groupby(\"customer_id\")[\"amount\"].sum().reset_index()\n",
        "    sessions = clickstream.groupby(\"customer_id\")[\"session_id\"].nunique().reset_index()\n",
        "\n",
        "    customer360 = crm.merge(spend, on=\"customer_id\", how=\"left\").merge(\n",
        "        sessions, on=\"customer_id\", how=\"left\"\n",
        "    )\n",
        "    customer360.to_csv(\"/tmp/customer360.csv\", index=False)\n",
        "\n",
        "def load():\n",
        "    df = pd.read_csv(\"/tmp/customer360.csv\")\n",
        "    df.to_csv(\"customer360_final.csv\", index=False)  # for BI dashboard\n",
        "\n",
        "# ---- DAG Definition ----\n",
        "default_args = {\n",
        "    \"owner\": \"airflow\",\n",
        "    \"start_date\": datetime(2024, 1, 1),\n",
        "    \"retries\": 1,\n",
        "}\n",
        "\n",
        "with DAG(\n",
        "    dag_id=\"customer_etl_pipeline\",\n",
        "    default_args=default_args,\n",
        "    schedule_interval=\"@daily\",\n",
        "    catchup=False,\n",
        ") as dag:\n",
        "\n",
        "    task_extract = PythonOperator(\n",
        "        task_id=\"extract\", python_callable=extract\n",
        "    )\n",
        "    task_transform = PythonOperator(\n",
        "        task_id=\"transform\", python_callable=transform\n",
        "    )\n",
        "    task_load = PythonOperator(\n",
        "        task_id=\"load\", python_callable=load\n",
        "    )\n",
        "\n",
        "    task_extract >> task_transform >> task_load\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Simulate DAG (Locally in Colab)\n",
        "# Simulate Airflow tasks manually\n",
        "extract()\n",
        "transform()\n",
        "load()\n",
        "\n",
        "# Check final output\n",
        "df = pd.read_csv(\"customer360_final.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "NC69HV6Nv9KJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}