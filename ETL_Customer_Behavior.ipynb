{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFngs2xaFX8E/AYuFY/iB2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BHARATH077/ETL_Customer_Behavior/blob/main/ETL_Customer_Behavior.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ETL Pipeline for Customer Behavior Analytics\n",
        "\n",
        "# Data Ingestion"
      ],
      "metadata": {
        "id": "fia2t7DdC87H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A0uMCyv81EE",
        "outputId": "7e50ecba-2713-4b7b-b857-00c0c2e106a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install Dependencies\n",
        "# Install Spark + DuckDB\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark duckdb pandas seaborn matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify Spark and DuckBD\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import duckdb\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"ETL_Project\").getOrCreate()\n",
        "print(\"Spark Version:\", spark.version)\n",
        "\n",
        "# Connect to DuckDB (in-memory for now)\n",
        "con = duckdb.connect(\":memory:\")\n",
        "print(\"DuckDB connected:\", con)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdiqeQqK9CIi",
        "outputId": "78b658b6-37cf-4251-9f15-9b403811f842"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Version: 3.5.1\n",
            "DuckDB connected: <duckdb.duckdb.DuckDBPyConnection object at 0x7bc8ca713db0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Sample Data\n",
        "# Since we don’t have real APIs/DBs yet, I’ll mock some CSV & JSON files directly in Colab (later we can replace them).\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Mock Clickstream CSV\n",
        "clickstream_data = {\n",
        "    \"session_id\": [1,2,3,4,5],\n",
        "    \"customer_id\": [101,102,101,103,104],\n",
        "    \"page_viewed\": [\"Home\",\"Product\",\"Cart\",\"Home\",\"Checkout\"],\n",
        "    \"timestamp\": [\"2024-01-01 10:00\",\"2024-01-01 10:05\",\"2024-01-01 10:10\",\"2024-01-02 12:00\",\"2024-01-02 12:15\"]\n",
        "}\n",
        "pd.DataFrame(clickstream_data).to_csv(\"clickstream.csv\", index=False)\n",
        "\n",
        "# Mock Transactions CSV\n",
        "transactions_data = {\n",
        "    \"transaction_id\": [1001,1002,1003],\n",
        "    \"customer_id\": [101,102,104],\n",
        "    \"amount\": [250.0, 100.0, 75.0],\n",
        "    \"timestamp\": [\"2024-01-01 11:00\",\"2024-01-01 11:05\",\"2024-01-02 12:30\"]\n",
        "}\n",
        "pd.DataFrame(transactions_data).to_csv(\"transactions.csv\", index=False)\n",
        "\n",
        "# Mock CRM JSON\n",
        "crm_data = [\n",
        "    {\"customer_id\":101, \"name\":\"Alice\",\"segment\":\"Premium\"},\n",
        "    {\"customer_id\":102, \"name\":\"Bob\",\"segment\":\"Standard\"},\n",
        "    {\"customer_id\":103, \"name\":\"Charlie\",\"segment\":\"Standard\"},\n",
        "    {\"customer_id\":104, \"name\":\"Diana\",\"segment\":\"Premium\"}\n",
        "]\n",
        "with open(\"crm.json\",\"w\") as f:\n",
        "    json.dump(crm_data,f)\n",
        "\n",
        "print(\"Sample data files created: clickstream.csv, transactions.csv, crm.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUv2CdO9Ni8",
        "outputId": "23a7c191-b2f7-4bee-ff46-d5fee63b0421"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data files created: clickstream.csv, transactions.csv, crm.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Raw Data Files\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read Clickstream CSV\n",
        "clickstream_df = pd.read_csv(\"clickstream.csv\")\n",
        "print(\"Clickstream:\")\n",
        "print(clickstream_df.head())\n",
        "\n",
        "# Read Transactions CSV\n",
        "transactions_df = pd.read_csv(\"transactions.csv\")\n",
        "print(\"\\nTransactions:\")\n",
        "print(transactions_df.head())\n",
        "\n",
        "# Read CRM JSON\n",
        "with open(\"crm.json\") as f:\n",
        "    crm_df = pd.json_normalize(json.load(f))\n",
        "print(\"\\nCRM:\")\n",
        "print(crm_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKlDFl-a_LVi",
        "outputId": "0eedb977-1c45-4064-86f6-3f4b5e628e75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clickstream:\n",
            "   session_id  customer_id page_viewed         timestamp\n",
            "0           1          101        Home  2024-01-01 10:00\n",
            "1           2          102     Product  2024-01-01 10:05\n",
            "2           3          101        Cart  2024-01-01 10:10\n",
            "3           4          103        Home  2024-01-02 12:00\n",
            "4           5          104    Checkout  2024-01-02 12:15\n",
            "\n",
            "Transactions:\n",
            "   transaction_id  customer_id  amount         timestamp\n",
            "0            1001          101   250.0  2024-01-01 11:00\n",
            "1            1002          102   100.0  2024-01-01 11:05\n",
            "2            1003          104    75.0  2024-01-02 12:30\n",
            "\n",
            "CRM:\n",
            "   customer_id     name   segment\n",
            "0          101    Alice   Premium\n",
            "1          102      Bob  Standard\n",
            "2          103  Charlie  Standard\n",
            "3          104    Diana   Premium\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load into DuckDB\n",
        "import duckdb\n",
        "\n",
        "# Create DuckDB connection\n",
        "con = duckdb.connect(database=':memory:')\n",
        "\n",
        "# Load Pandas DataFrames into DuckDB\n",
        "con.register(\"clickstream_df\", clickstream_df)\n",
        "con.register(\"transactions_df\", transactions_df)\n",
        "con.register(\"crm_df\", crm_df)\n",
        "\n",
        "# Create DuckDB tables\n",
        "con.execute(\"CREATE TABLE clickstream AS SELECT * FROM clickstream_df\")\n",
        "con.execute(\"CREATE TABLE transactions AS SELECT * FROM transactions_df\")\n",
        "con.execute(\"CREATE TABLE crm AS SELECT * FROM crm_df\")\n",
        "\n",
        "# Verify\n",
        "print(con.execute(\"SHOW TABLES\").fetchdf())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUGLKv4r_tDs",
        "outputId": "e2eb3895-c62a-47b0-fbe5-e575c3c85a59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              name\n",
            "0      clickstream\n",
            "1   clickstream_df\n",
            "2              crm\n",
            "3           crm_df\n",
            "4     transactions\n",
            "5  transactions_df\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run First Warehouse Queries\n",
        "\n",
        "# Count clickstream sessions\n",
        "print(con.execute(\"SELECT COUNT(*) as sessions FROM clickstream\").fetchdf())\n",
        "\n",
        "# Check total transactions\n",
        "print(con.execute(\"SELECT COUNT(*) as transactions FROM transactions\").fetchdf())\n",
        "\n",
        "# Join CRM with Transactions (quick test)\n",
        "query = \"\"\"\n",
        "SELECT c.customer_id, c.name, c.segment, SUM(t.amount) as total_spend\n",
        "FROM crm c\n",
        "LEFT JOIN transactions t\n",
        "ON c.customer_id = t.customer_id\n",
        "GROUP BY c.customer_id, c.name, c.segment\n",
        "\"\"\"\n",
        "print(con.execute(query).fetchdf())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0RYJozIAUcs",
        "outputId": "d410f366-1010-4c7d-cb84-23d420bbd3a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sessions\n",
            "0         5\n",
            "   transactions\n",
            "0             3\n",
            "   customer_id     name   segment  total_spend\n",
            "0          102      Bob  Standard        100.0\n",
            "1          101    Alice   Premium        250.0\n",
            "2          104    Diana   Premium         75.0\n",
            "3          103  Charlie  Standard          NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning & Transformation with PySpark"
      ],
      "metadata": {
        "id": "6l3zPA2tCjHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import Spark\n",
        "\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, upper\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"ETL_Cleaning\").getOrCreate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o44PACBAzIo",
        "outputId": "a0197f14-5001-45a0-9e54-7db0ee412723"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data into Spark\n",
        "# Load CSVs into Spark DataFrames\n",
        "clickstream_spark = spark.read.csv(\"clickstream.csv\", header=True, inferSchema=True)\n",
        "transactions_spark = spark.read.csv(\"transactions.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Load JSON CRM into Spark\n",
        "crm_spark = spark.read.json(\"crm.json\")\n",
        "\n",
        "print(\"Clickstream:\")\n",
        "clickstream_spark.show()\n",
        "print(\"Transactions:\")\n",
        "transactions_spark.show()\n",
        "print(\"CRM:\")\n",
        "crm_spark.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8p76mesDk2b",
        "outputId": "2f1ce737-7448-4dad-e2fc-3c89dc106c57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clickstream:\n",
            "+----------+-----------+-----------+-------------------+\n",
            "|session_id|customer_id|page_viewed|          timestamp|\n",
            "+----------+-----------+-----------+-------------------+\n",
            "|         1|        101|       Home|2024-01-01 10:00:00|\n",
            "|         2|        102|    Product|2024-01-01 10:05:00|\n",
            "|         3|        101|       Cart|2024-01-01 10:10:00|\n",
            "|         4|        103|       Home|2024-01-02 12:00:00|\n",
            "|         5|        104|   Checkout|2024-01-02 12:15:00|\n",
            "+----------+-----------+-----------+-------------------+\n",
            "\n",
            "Transactions:\n",
            "+--------------+-----------+------+-------------------+\n",
            "|transaction_id|customer_id|amount|          timestamp|\n",
            "+--------------+-----------+------+-------------------+\n",
            "|          1001|        101| 250.0|2024-01-01 11:00:00|\n",
            "|          1002|        102| 100.0|2024-01-01 11:05:00|\n",
            "|          1003|        104|  75.0|2024-01-02 12:30:00|\n",
            "+--------------+-----------+------+-------------------+\n",
            "\n",
            "CRM:\n",
            "+-----------+-------+--------+\n",
            "|customer_id|   name| segment|\n",
            "+-----------+-------+--------+\n",
            "|        101|  Alice| Premium|\n",
            "|        102|    Bob|Standard|\n",
            "|        103|Charlie|Standard|\n",
            "|        104|  Diana| Premium|\n",
            "+-----------+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Cleaning\n",
        "\n",
        "# Convert timestamps\n",
        "clickstream_spark = clickstream_spark.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
        "transactions_spark = transactions_spark.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
        "\n",
        "# Standardize: make customer_id uppercase in CRM (simulate cleaning)\n",
        "crm_spark = crm_spark.withColumn(\"segment\", upper(col(\"segment\")))\n",
        "\n",
        "# Drop rows with missing customer_id\n",
        "clickstream_spark = clickstream_spark.na.drop(subset=[\"customer_id\"])\n",
        "transactions_spark = transactions_spark.na.drop(subset=[\"customer_id\"])\n",
        "crm_spark = crm_spark.na.drop(subset=[\"customer_id\"])\n"
      ],
      "metadata": {
        "id": "XQHO6_9KD1iJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Cleaned Data\n",
        "\n",
        "import duckdb\n",
        "\n",
        "# Collect Spark DF → Pandas → load into DuckDB\n",
        "con = duckdb.connect(database=':memory:')\n",
        "con.register(\"clickstream_clean\", clickstream_spark.toPandas())\n",
        "con.register(\"transactions_clean\", transactions_spark.toPandas())\n",
        "con.register(\"crm_clean\", crm_spark.toPandas())\n",
        "\n",
        "# Save as DuckDB tables\n",
        "con.execute(\"CREATE TABLE clickstream_clean AS SELECT * FROM clickstream_clean\")\n",
        "con.execute(\"CREATE TABLE transactions_clean AS SELECT * FROM transactions_clean\")\n",
        "con.execute(\"CREATE TABLE crm_clean AS SELECT * FROM crm_clean\")\n",
        "\n",
        "print(con.execute(\"SHOW TABLES\").fetchdf())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myDU3pK-EErv",
        "outputId": "12b9f074-014e-4045-b268-208fdc59f1ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 name\n",
            "0   clickstream_clean\n",
            "1   clickstream_clean\n",
            "2           crm_clean\n",
            "3           crm_clean\n",
            "4  transactions_clean\n",
            "5  transactions_clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify Cleaning\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT c.customer_id, c.name, c.segment, COUNT(s.session_id) as sessions, SUM(t.amount) as total_spend\n",
        "FROM crm_clean c\n",
        "LEFT JOIN clickstream_clean s ON c.customer_id = s.customer_id\n",
        "LEFT JOIN transactions_clean t ON c.customer_id = t.customer_id\n",
        "GROUP BY c.customer_id, c.name, c.segment\n",
        "\"\"\"\n",
        "print(con.execute(query).fetchdf())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIWIfI0FEIw4",
        "outputId": "4708eb80-50e1-49e0-e3b0-0e353b7477b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   customer_id     name   segment  sessions  total_spend\n",
            "0          104    Diana   PREMIUM         1         75.0\n",
            "1          103  Charlie  STANDARD         1          NaN\n",
            "2          101    Alice   PREMIUM         2        500.0\n",
            "3          102      Bob  STANDARD         1        100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75m-1XxjEMuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}